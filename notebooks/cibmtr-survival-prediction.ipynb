{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11009cbe",
   "metadata": {},
   "source": [
    "## CIBMTR Survival Prediction\n",
    "    This notebook demonstrates how to build **machine learning and survival analysis models** to predict patient survival using the CIBMTR dataset.\n",
    "    \n",
    "    **Workflow**\n",
    "    1. Data Loading & Preprocessing\n",
    "    2. Exploratory Data Analysis (EDA)\n",
    "    3. Feature Engineering\n",
    "    4. Model Training (Logistic Regression, Random Forest, XGBoost)\n",
    "    5. Evaluation (Accuracy, ROC-AUC, Log-loss)\n",
    "    6. Survival Analysis (Kaplan-Meier, CoxPH)\n",
    "    7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b908dc9",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "  Import libraries and helper functions from `src/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.preprocessing import load_data, preprocess_data\n",
    "from src.modeling import train_logistic, train_random_forest, train_xgboost\n",
    "from src.evaluation import evaluate_classifier, plot_feature_importance, survival_analysis, cox_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef4fe9",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "  The CIBMTR dataset should be placed inside the `data/` folder.\n",
    "  For privacy reasons, raw data is **not included** in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bdbb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.4)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Arjun Girish/cibtr-survival-prediction/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data_path = \"/data/cibmtr.csv \" # replace with actual file name\n",
    "df = load_data(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b69ac",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "  - Handle categorical variables\n",
    "  - Scale numerical features\n",
    "  - Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c110f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_data(df, target=\"survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f31f2",
   "metadata": {},
   "source": [
    "## 4. Train Models\n",
    "  We compare **Logistic Regression, Random Forest, and XGBoost**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = train_logistic(X_train, y_train)\n",
    "rf = train_random_forest(X_train, y_train)\n",
    "xgb = train_xgboost(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee22efb",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "  We use **accuracy, ROC-AUC, and log-loss** for model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd200dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression\": evaluate_classifier(log_reg, X_test, y_test),\n",
    "    \"Random Forest\": evaluate_classifier(rf, X_test, y_test),\n",
    "    \"XGBoost\": evaluate_classifier(xgb, X_test, y_test)\n",
    "}\n",
    "pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789afebf",
   "metadata": {},
   "source": [
    "### Feature Importance (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rf, X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75685b3",
   "metadata": {},
   "source": [
    "## 6. Survival Analysis\n",
    "Using **Kaplan-Meier** and **Cox Proportional Hazards**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d530fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example survival analysis (requires time-to-event + event indicator columns)\n",
    "survival_analysis(df, time_col=\"time_to_event\", event_col=\"event\")\n",
    "\n",
    "# Cox Proportional Hazards\n",
    "cox_analysis(df, time_col=\"time_to_event\", event_col=\"event\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec04bc",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "- Random Forest and XGBoost provide strong predictive performance.  \n",
    "- Kaplan-Meier curves give a clear view of survival probabilities.  \n",
    "- CoxPH provides interpretability of covariates.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
